# Guide d'am√©lioration des Agents AI / AI Agent Enhancement Guide

## üöÄ Vue d'ensemble / Overview

Le syst√®me SignalTrust AI Scanner a √©t√© am√©lior√© avec des capacit√©s d'IA de pointe utilisant de vrais mod√®les d'IA au lieu de simulations.

The SignalTrust AI Scanner system has been enhanced with state-of-the-art AI capabilities using real AI models instead of simulations.

## üéØ Am√©liorations / Improvements

### Avant / Before
- ‚ùå Pr√©dictions al√©atoires et simul√©es
- ‚ùå Aucune vraie intelligence artificielle
- ‚ùå Analyses basiques limit√©es
- ‚ùå Pas d'apprentissage r√©el

### Apr√®s / After
- ‚úÖ Vrais mod√®les d'IA (GPT-4, Claude, mod√®les locaux)
- ‚úÖ Analyses intelligentes et contextuelles
- ‚úÖ Pr√©dictions bas√©es sur l'apprentissage profond
- ‚úÖ Support de multiples fournisseurs d'IA
- ‚úÖ Fallback automatique si l'IA n'est pas disponible

## üì¶ Providers AI disponibles / Available AI Providers

### 1. OpenAI (GPT-4, GPT-3.5-turbo)
**Avantages:**
- Tr√®s performant pour l'analyse de march√©s
- Excellent en compr√©hension contextuelle
- Large base de connaissances

**Configuration:**
```bash
# Dans votre fichier .env
AI_PROVIDER=openai
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4
```

**Co√ªt approximatif:**
- GPT-4: ~$0.03 per 1K tokens input, ~$0.06 per 1K tokens output
- GPT-3.5-turbo: ~$0.001 per 1K tokens

### 2. Anthropic (Claude)
**Avantages:**
- Excellent pour l'analyse d√©taill√©e
- Bonne compr√©hension des donn√©es financi√®res
- R√©ponses plus nuanc√©es

**Configuration:**
```bash
# Dans votre fichier .env
AI_PROVIDER=anthropic
ANTHROPIC_API_KEY=sk-ant-your-key-here
ANTHROPIC_MODEL=claude-3-sonnet-20240229
```

**Co√ªt approximatif:**
- Claude 3 Opus: ~$15/$75 per MTok
- Claude 3 Sonnet: ~$3/$15 per MTok
- Claude 3 Haiku: ~$0.25/$1.25 per MTok

### 3. Mod√®les Locaux (Ollama)
**Avantages:**
- Gratuit et priv√©
- Pas de d√©pendance externe
- Contr√¥le total

**Installation Ollama:**
```bash
# Linux/Mac
curl -fsSL https://ollama.ai/install.sh | sh

# D√©marrer Ollama
ollama serve

# T√©l√©charger un mod√®le
ollama pull llama2
ollama pull mistral
```

**Configuration:**
```bash
# Dans votre fichier .env
AI_PROVIDER=local
LOCAL_MODEL=llama2
LOCAL_API_URL=http://localhost:11434
```

## üîß Installation et Configuration

### √âtape 1: Installer les d√©pendances

```bash
# Installation compl√®te avec tous les providers
pip install -r requirements.txt

# Ou installation s√©lective
pip install openai  # Pour OpenAI uniquement
pip install anthropic  # Pour Anthropic uniquement
```

### √âtape 2: Cr√©er le fichier .env

```bash
# Copier l'exemple
cp .env.example .env

# √âditer avec vos cl√©s API
nano .env
```

### √âtape 3: Configurer votre provider pr√©f√©r√©

**Option A: OpenAI (Recommand√© pour la performance)**
```bash
AI_PROVIDER=openai
OPENAI_API_KEY=sk-proj-xxxxx
OPENAI_MODEL=gpt-4
USE_AI_PREDICTIONS=true
USE_AI_ANALYSIS=true
```

**Option B: Anthropic (Recommand√© pour l'analyse d√©taill√©e)**
```bash
AI_PROVIDER=anthropic
ANTHROPIC_API_KEY=sk-ant-xxxxx
ANTHROPIC_MODEL=claude-3-sonnet-20240229
USE_AI_PREDICTIONS=true
USE_AI_ANALYSIS=true
```

**Option C: Local (Gratuit mais n√©cessite ressources)**
```bash
AI_PROVIDER=local
LOCAL_MODEL=mistral
LOCAL_API_URL=http://localhost:11434
USE_AI_PREDICTIONS=true
USE_AI_ANALYSIS=true
```

### √âtape 4: Tester l'installation

```python
# Test rapide
python3 -c "from ai_provider import EnhancedAIEngine; ai = EnhancedAIEngine(); print('‚úÖ AI Engine OK')"
```

## üí° Utilisation / Usage

### Dans votre code Python

```python
from ai_predictor import AIPredictor

# Cr√©er un predictor avec vraie IA
predictor = AIPredictor(use_real_ai=True)

# Pr√©diction de prix
result = predictor.predict_price('AAPL', days_ahead=7)
print(result)

# G√©n√©ration de signaux
signals = predictor.generate_signals('BTC')
print(signals)
```

### Via l'API web

L'application Flask utilisera automatiquement l'IA configur√©e:

```bash
# D√©marrer l'application
python3 start.py

# L'application d√©tectera automatiquement:
# ‚úÖ Quelle IA est configur√©e
# ‚úÖ Si les cl√©s API sont valides
# ‚úÖ Utilisera le fallback si n√©cessaire
```

## üéì Obtenir des cl√©s API

### OpenAI
1. Visitez: https://platform.openai.com/signup
2. Cr√©ez un compte
3. Allez dans API Keys: https://platform.openai.com/api-keys
4. Cr√©ez une nouvelle cl√©
5. Ajoutez des cr√©dits (minimum $5)

### Anthropic
1. Visitez: https://console.anthropic.com/
2. Cr√©ez un compte
3. Allez dans API Keys
4. Cr√©ez une nouvelle cl√©
5. Ajoutez des cr√©dits

### Ollama (Local - Gratuit)
1. Installez: https://ollama.ai/download
2. Lancez: `ollama serve`
3. T√©l√©chargez un mod√®le: `ollama pull llama2`
4. Pas de cl√© API n√©cessaire!

## üìä Comparaison des Performances

| Provider | Qualit√© | Vitesse | Co√ªt | Priv√© |
|----------|---------|---------|------|-------|
| GPT-4 | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | $$$ | ‚ùå |
| GPT-3.5-turbo | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | $ | ‚ùå |
| Claude 3 Opus | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | $$$$ | ‚ùå |
| Claude 3 Sonnet | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | $$ | ‚ùå |
| Llama 2 (Local) | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | GRATUIT | ‚úÖ |
| Mistral (Local) | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | GRATUIT | ‚úÖ |

## üîí S√©curit√© / Security

**Important:**
- ‚ùå Ne committez JAMAIS votre fichier .env avec de vraies cl√©s
- ‚úÖ Utilisez des variables d'environnement en production
- ‚úÖ Rotez vos cl√©s API r√©guli√®rement
- ‚úÖ Limitez les permissions des cl√©s API
- ‚úÖ Surveillez l'utilisation pour √©viter les co√ªts √©lev√©s

## üêõ D√©pannage / Troubleshooting

### L'IA ne fonctionne pas

```bash
# V√©rifier que les d√©pendances sont install√©es
pip list | grep -E "openai|anthropic"

# V√©rifier les cl√©s API
python3 -c "import os; from dotenv import load_dotenv; load_dotenv(); print('OPENAI_API_KEY:', 'Configured' if os.getenv('OPENAI_API_KEY') else 'Missing')"

# Tester la connexion
python3 -c "from ai_provider import EnhancedAIEngine; ai = EnhancedAIEngine(); print(ai.provider)"
```

### Erreur "Module not found: openai"

```bash
pip install openai anthropic
```

### Ollama ne d√©marre pas

```bash
# V√©rifier si Ollama est install√©
ollama --version

# D√©marrer Ollama en debug
OLLAMA_DEBUG=1 ollama serve

# V√©rifier les mod√®les install√©s
ollama list
```

### Co√ªts trop √©lev√©s

**Solutions:**
1. Utilisez GPT-3.5-turbo au lieu de GPT-4
2. R√©duisez MAX_TOKENS dans .env
3. Passez √† Claude Haiku (moins cher)
4. Utilisez un mod√®le local (gratuit)

## üìà Am√©lioration Continue

Le syst√®me apprend et s'am√©liore avec:
- Chaque analyse de march√© effectu√©e
- Feedback sur la pr√©cision des pr√©dictions
- Patterns d√©tect√©s dans les donn√©es historiques

## üÜò Support

Pour toute question ou probl√®me:
1. Consultez la documentation: README.md
2. V√©rifiez les issues GitHub
3. Contactez: support@signaltrust.ai

## üìù Changelog

### Version 3.0.0 (2026-02-07)
- ‚ú® Ajout du syst√®me AI Provider multi-fournisseur
- ‚ú® Support OpenAI GPT-4 et GPT-3.5-turbo
- ‚ú® Support Anthropic Claude 3
- ‚ú® Support mod√®les locaux via Ollama
- ‚ú® Fallback automatique vers simulation
- ‚ú® Configuration flexible via .env
- üîß Am√©lioration des pr√©dictions
- üîß Am√©lioration de l'analyse de march√©
- üìö Documentation compl√®te en fran√ßais/anglais

---

**Fait avec ‚ù§Ô∏è par SignalTrust AI**
